{
    "collab_server" : "",
    "contents" : "---\ntitle: \"クラスタリングのお勉強ノート\"\nauthor: \"yoshi\"\ndate: '2016-08-16'\noutput:\n  html_document:\n    number_section: yes\n    smart: yes\n    toc: yes\n    toc_depth: 2\n---\n\n# K-meansクラスタリング\nIrvineのワインデータセットを使う。\n```{r, message=TRUE}\ndf <- read.table(\"../data/wine.data\", header = TRUE, sep=\",\")\nhead(df)\n```\n一列目は教師ラベルであるからクラスタリングをするときは取り除く。\n```{r}\ndfNoTeacher <- df[,2:14]\n```\n３つのクラスに分類する。\n```{r,message=TRUE}\nwineK3 <- kmeans(x = dfNoTeacher, centers = 3)\nwineK3\n```\nPCAして可視化する。{useful}パッケージでplotをoverrideすると簡単にkmeansの結果を可視化できる。\n```{r}\nrequire(useful)\nplot(wineK3, data=dfNoTeacher)\n```  \n\n通常クラスタリングをするとき、クラスタ数は事前に分からない。クラス数の決め方としてハーティガンルールがある。{useful}パッケージにはハーティガン数を計算する関数が用意されている。  \n\n```{r, message=TRUE}\nwineGrid <- FitKMeans(x=dfNoTeacher, max.clusters = 20L, nstart = 30, iter.max = 20L)\nwineGrid\n```\n```{r}\nPlotHartigan(wineGrid)\n```\nハーティガンルールによればクラス数は15にするべきである。\n```{r}\nwineK15 <- kmeans(x = dfNoTeacher, centers = 15)\nplot(wineK15, data=dfNoTeacher)\n```\n\n# K-medoids法\nK-meansは質的変数には使えない、外れ値に敏感であるという問題がある。\n```{r}\nindicators <- c(\"BX.KLT.DINV.WD.GD.ZS\", \"NY.GDP.DEFL.KD.ZG\",\n\"NY.GDP.MKTP.CD\", \"NY.GDP.MKTP.KD.ZG\",\n\"NY.GDP.PCAP.CD\", \"NY.GDP.PCAP.KD.ZG\",\n\"TG.VAL.TOTL.GD.ZS\")\nrequire(WDI)\n# リストの中にあるすべての国のインジケータを引っ張ってくる\n# すべての国が各指標を持ってはいない\n# いくつかの国はデータが全くない\nwbInfo <- WDI(country = \"all\" , indicator = indicators , start = 2011 ,\nend = 2011 , extra = TRUE)\n# 集約した情報を除く\nwbInfo <- wbInfo[wbInfo$region != \"Aggregates\" ,]\n# すべてのインジケータがNAの国を除く\nwbInfo <- wbInfo[which(rowSums(!is.na(wbInfo[, indicators])) > 0) ,]\n# ISOが無い行を除く\nwbInfo <- wbInfo[!is.na(wbInfo$iso2c) ,]\n\n# 国名を知ることができるようにrownamesを設定する\nrownames(wbInfo) <- wbInfo$iso2c\n# 地域を再度ファクター型に、収入や貸付は水準の変化を考慮する\nwbInfo$region <- factor(wbInfo$region)\nwbInfo$income <- factor(wbInfo$income)\nwbInfo$lending <- factor(wbInfo$lending)\n```\n```{r}\n# 保持する列を見つける\nkeep.cols <- which(!names(wbInfo) %in% c(\"iso2c\" , \"country\" , \"year\" ,\n \"capital\" , \"iso3c\"))\nrequire(cluster)\n# クラスタリングを適応\nwbPam <- pam(x = wbInfo[, keep.cols] , k = 3 , keep.diss = TRUE ,\n keep.data = TRUE)\n# medoidデータを確認\nwbPam$medoids\n```\n\n各点のシルエット値は、他のクラスターの点と比べて、その点が自身のクラスター内の他の点にどれくらい相似しているかを示す尺度です。$i$ 番目の点のシルエット値 $S_i$ は、次のように定義されます。\n$$\nS_i = (b_i-a_i)/ max(a_i,b_i)\n$$\nここで $a_i$ は $i$ 番目の点から $i$ と同じクラスターの他の点までの平均距離で、$b_i$ は $i$ 番目の点から別のクラスターの点までの最小平均距離です。\n\nシルエットをプロットする。\n```{r, message=TRUE}\nplot(wbPam, which.plots = 2)\n```\n\n# 階層型クラスタリング\n階層的クラスタリングは質的変数にも使うことが出来るが、ここでは量的変数のみを含む\nワインデータを使い階層型クラスタリングする。\n```{r}\nwineH <- hclust(d = dist(dfNoTeacher))\nplot(wineH)\n```\n　階層的クラスタリングによって生成され得られた木を切断して、定義されたグループ\nへデータを分割します。分割の方法は2つあり、カットが行われる高さを\n指定する方法と、いくつクラスタを作るのかを指定する方法があります。\n```{r}\n# 分割数を指定する方法\nplot(wineH)\nrect.hclust(wineH , k = 3 , border = \"blue\")\n```\n\n```{r}\n# 高さを指定する方法\nplot(wineH)\nrect.hclust(wineH , h = 800 , border = \"blue\")\n```\n\n木を切断するには`cutree`を使う。\n```{r}\ncutree(wineH, k=3)\n```\n\n\n***\n# 参考文献  \n- みんなのR,22章\n- Help of MATLAB, kmedoids",
    "created" : 1471232452068.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3479991265",
    "id" : "1BC0A60F",
    "lastKnownWriteTime" : 1471405088,
    "last_content_update" : 1471443389107,
    "path" : "~/Documents/petraWorkspace/R/clustering/doc/clustering.Rmd",
    "project_path" : "doc/clustering.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "marks" : "<:81,47\n>:81,55",
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}